import cv2
import streamlit as st
import json
import tempfile
import os

from utils.framer import extract_frames
from demo_functions import load_model, predict_gesture, frames_to_video

MODEL_PATH = r".\checkpoints\Bukva\best_train_bukva.pth"
CONFIG_PATH = r".\src\hyperparameters\Bukva\config.json"
LABEL_MAP_PATH = r".\src\datasets\bukva_label_map.csv"

st.title("‚úåÔ∏è –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç–µ–ª—å –†–ñ–Ø (–î–∞–∫—Ç–∏–ª—å) - –†–µ–∂–∏–º –≤–∏–¥–µ–æ—Ñ–∞–π–ª–∞")
st.markdown("""
–ó–∞–≥—Ä—É–∑–∏—Ç–µ –≤–∏–¥–µ–æ—Ñ–∞–π–ª
""")

if 'uploaded_video' not in st.session_state:
    st.session_state.uploaded_video = None
if 'extracted_frames' not in st.session_state:
    st.session_state.extracted_frames = []
if 'recognition_result' not in st.session_state:
    st.session_state.recognition_result = None
if 'top3_result' not in st.session_state:
    st.session_state.top3_result = None

st.sidebar.header("üìÅ –ó–∞–≥—Ä—É–∑–∫–∞ –≤–∏–¥–µ–æ")

uploaded_file = st.sidebar.file_uploader(
    "–í—ã–±–µ—Ä–∏—Ç–µ –≤–∏–¥–µ–æ—Ñ–∞–π–ª (MP4, AVI, MOV)",
    type=['mp4', 'avi', 'mov', 'mkv', 'wmv']
)

import base64
def autoplay_video(video_path):
    """
    –í–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç –≤–∏–¥–µ–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ (–±–µ–∑ –∑–≤—É–∫–∞, —Å –∑–∞—Ü–∏–∫–ª–∏–≤–∞–Ω–∏–µ–º –ø–æ –∂–µ–ª–∞–Ω–∏—é)
    """
    with open(video_path, "rb") as f:
        video_bytes = f.read()
    video_base64 = base64.b64encode(video_bytes).decode("utf-8")
    
    video_html = f"""
    <video autoplay muted loop playsinline style="width: 100%; max-width: 600px; height: auto;">
        <source src="data:video/mp4;base64,{video_base64}" type="video/mp4">
        –í–∞—à –±—Ä–∞—É–∑–µ—Ä –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –≤–∏–¥–µ–æ.
    </video>
    """
    st.markdown(video_html, unsafe_allow_html=True)

if uploaded_file is not None:
    temp_video_path = f"temp_{uploaded_file.name}"
    with open(temp_video_path, "wb") as f:
        f.write(uploaded_file.getbuffer())
    
    st.session_state.uploaded_video = temp_video_path
    
    st.sidebar.success(f"–§–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω: {uploaded_file.name}")
    
    if st.sidebar.button("üé¨ –†–∞—Å–ø–æ–∑–Ω–∞—Ç—å –∂–µ—Å—Ç", type="primary"):
        with st.spinner("–ò–∑–≤–ª–µ–∫–∞–µ–º –∫–∞–¥—Ä—ã –∏–∑ –≤–∏–¥–µ–æ..."):
            with open(CONFIG_PATH, 'r') as f:
                config = json.load(f)
                n_frames = config['data']['n_frames']
            
            frames_RGB = extract_frames(
                video_path=temp_video_path,
                num_frames=n_frames,
                method='window',
                resize_flag=True
            )
            frames = []
            for frame in frames_RGB:
                frames.append(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))

            if frames:
                st.session_state.extracted_frames = frames
                
                with st.expander("üì∑ –ò–∑–≤–ª–µ—á—ë–Ω–Ω—ã–µ –∫–∞–¥—Ä—ã –∏–∑ –≤–∏–¥–µ–æ"):
                    cols = st.columns(10)
                    for idx, frame in enumerate(frames):
                        with cols[idx % 10]:
                            st.image(frame, caption=f"–ö–∞–¥—Ä {idx}", width=50)
                
                with st.spinner("üé• –°–æ–∑–¥–∞—ë–º –≤–∏–¥–µ–æ –∏–∑ –∫–∞–¥—Ä–æ–≤..."):
                    with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as tmpfile:
                        frame_video_path = tmpfile.name
                    try:
                        frames_to_video(frames, frame_video_path, fps=20)

                        if not os.path.exists(frame_video_path):
                            st.error("–í–∏–¥–µ–æ –Ω–µ —Å–æ–∑–¥–∞–Ω–æ")
                            
                        if os.path.getsize(frame_video_path) == 0:
                            st.error("–í–∏–¥–µ–æ –ø—É—Å—Ç–æ–µ (0 –±–∞–π—Ç)")
                            
                        #with open(frame_video_path, "rb") as f:
                        #    st.video(f.read())
                        autoplay_video(frame_video_path)
                    
                    finally:
                        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
                        os.unlink(frame_video_path)
                        if os.path.exists(frame_video_path):
                            os.unlink(frame_video_path)
                
                if st.session_state.model:
                    with st.spinner("ü§ñ –†–∞—Å–ø–æ–∑–Ω–∞–µ–º –∂–µ—Å—Ç..."):
                        gesture, confidence, top3_list = predict_gesture(
                            st.session_state.model,
                            frames,
                            LABEL_MAP_PATH
                            )
                        st.session_state.recognition_result = (gesture, confidence)
                        st.session_state.top3_result = top3_list
                        
                        st.success(f"""
                        ## üéØ **–ë—É–∫–≤–∞: {gesture}**
                        –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.1%}
                        """)
                        
                        if top3_list:
                            st.subheader("üèÜ –¢–æ–ø-3 –ø–æ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏")
                            cols = st.columns(3)
                            for i, (name, prob) in enumerate(top3_list):
                                with cols[i]:
                                    medal_color = ["#FFD700", "#C0C0C0", "#CD7F32"][i]
                                    st.markdown(f"<h4 style='text-align: center; color: {medal_color};'>{i+1} –º–µ—Å—Ç–æ</h4>", unsafe_allow_html=True)
                                    st.markdown(f"<h3 style='text-align: center;'>{name}</h3>", unsafe_allow_html=True)
                                    st.progress(float(prob))
                                    st.markdown(f"<p style='text-align: center;'>{prob:.1%}</p>", unsafe_allow_html=True)
                        else:
                            st.info("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã.")
                else:
                    st.error("–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")
            else:
                st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –∫–∞–¥—Ä—ã –∏–∑ –≤–∏–¥–µ–æ")

if st.session_state.recognition_result:
    gesture, confidence = st.session_state.recognition_result
    st.sidebar.subheader("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç")
    st.sidebar.metric("–ë—É–∫–≤–∞", gesture)
    st.sidebar.metric("–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å", f"{confidence:.1%}")

with st.expander("‚ÑπÔ∏è –ö–∞–∫ —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç"):
    st.markdown("""
    1. **–ó–∞–≥—Ä—É–∑–∏—Ç–µ –≤–∏–¥–µ–æ—Ñ–∞–π–ª** —Å –∂–µ—Å—Ç–æ–º (MP4, AVI, MOV –∏ –¥—Ä—É–≥–∏–µ —Ñ–æ—Ä–º–∞—Ç—ã)
    2. **–°–∏—Å—Ç–µ–º–∞ –∏–∑–≤–ª–µ—á—ë—Ç –∫–∞–¥—Ä—ã** –∏–∑ –≤–∏–¥–µ–æ
    3. **–ö–∞–¥—Ä—ã –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è** (–∏–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞, –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è)
    4. **–ú–æ–¥–µ–ª—å –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∫–∞–¥—Ä–æ–≤** –∏ —Ä–∞—Å–ø–æ–∑–Ω–∞—ë—Ç –∂–µ—Å—Ç
    5. **–û—Ç–æ–±—Ä–∞–∂–∞–µ—Ç—Å—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç** —Å —É–∫–∞–∑–∞–Ω–∏–µ–º —É—Ä–æ–≤–Ω—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
    """)

if 'model' not in st.session_state:
    with st.spinner("–ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è..."):
        st.session_state.model = load_model(CONFIG_PATH, MODEL_PATH)

st.divider()
st.caption("–°–∏—Å—Ç–µ–º–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –†–ñ–Ø (–î–∞–∫—Ç–∏–ª—å) | –†–µ–∂–∏–º –≤–∏–¥–µ–æ—Ñ–∞–π–ª–∞")